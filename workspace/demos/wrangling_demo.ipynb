{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Data Wrangling Demo\n",
    "\n",
    "This notebook demonstrates common data wrangling techniques using PySpark with Delta tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"hds_sparkhive_demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+\n",
      "| id| name|      date|age|\n",
      "+---+-----+----------+---+\n",
      "|  1|Alice|2023-01-01| 23|\n",
      "|  2|  Bob|2023-01-02| 30|\n",
      "|  3|Cathy|2023-01-02| 45|\n",
      "|  4|David|2023-01-03| 35|\n",
      "|  5|  Eve|2023-01-03| 29|\n",
      "|  6|Frank|2023-01-01| 23|\n",
      "+---+-----+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", \"2023-01-01\", 23),\n",
    "    (2, \"Bob\", \"2023-01-02\", 30),\n",
    "    (3, \"Cathy\", \"2023-01-02\", 45),\n",
    "    (4, \"David\", \"2023-01-03\", 35),\n",
    "    (5, \"Eve\", \"2023-01-03\", 29),\n",
    "    (6, \"Frank\", \"2023-01-01\", 23)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"date\", \"age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to Delta table `demo_db.people`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database if not exists (not allowed in restricted environments)\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo_db\")\n",
    "\n",
    "# Save dataframe as Delta table\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"demo_db.people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load table from database.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+\n",
      "| id| name|      date|age|\n",
      "+---+-----+----------+---+\n",
      "|  6|Frank|2023-01-01| 23|\n",
      "|  1|Alice|2023-01-01| 23|\n",
      "|  3|Cathy|2023-01-02| 45|\n",
      "|  4|David|2023-01-03| 35|\n",
      "|  5|  Eve|2023-01-03| 29|\n",
      "|  2|  Bob|2023-01-02| 30|\n",
      "+---+-----+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df = spark.table(\"demo_db.people\")\n",
    "people_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  6|Frank|\n",
      "|  1|Alice|\n",
      "|  3|Cathy|\n",
      "|  4|David|\n",
      "|  5|  Eve|\n",
      "|  2|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.select(\"id\", \"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+-----------+\n",
      "| id| name|      date|age|age_plus_10|\n",
      "+---+-----+----------+---+-----------+\n",
      "|  6|Frank|2023-01-01| 23|         33|\n",
      "|  1|Alice|2023-01-01| 23|         33|\n",
      "|  3|Cathy|2023-01-02| 45|         55|\n",
      "|  4|David|2023-01-03| 35|         45|\n",
      "|  5|  Eve|2023-01-03| 29|         39|\n",
      "|  2|  Bob|2023-01-02| 30|         40|\n",
      "+---+-----+----------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df = people_df.withColumn(\"age_plus_10\", F.col(\"age\") + 10)\n",
    "people_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+-----------+\n",
      "| id| name|      date|age|age_plus_10|\n",
      "+---+-----+----------+---+-----------+\n",
      "|  3|Cathy|2023-01-02| 45|         55|\n",
      "|  4|David|2023-01-03| 35|         45|\n",
      "+---+-----+----------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame API\n",
    "people_df.filter(F.col(\"age\") > 30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e32088f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+-----------+\n",
      "| id| name|      date|age|age_plus_10|\n",
      "+---+-----+----------+---+-----------+\n",
      "|  3|Cathy|2023-01-02| 45|         55|\n",
      "|  4|David|2023-01-03| 35|         45|\n",
      "+---+-----+----------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using SQL expression string\n",
    "people_df.filter(\"age > 30\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins\n",
    "\n",
    "Create a second DataFrame to join with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|state|\n",
      "+---+-----+\n",
      "|  1|   NY|\n",
      "|  2|   CA|\n",
      "|  3|   TX|\n",
      "|  7|   WA|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = [\n",
    "    (1, \"NY\"),\n",
    "    (2, \"CA\"),\n",
    "    (3, \"TX\"),\n",
    "    (7, \"WA\")\n",
    "]\n",
    "columns2 = [\"id\", \"state\"]\n",
    "df2 = spark.createDataFrame(data2, columns2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+-----------+-----+\n",
      "| id| name|      date|age|age_plus_10|state|\n",
      "+---+-----+----------+---+-----------+-----+\n",
      "|  1|Alice|2023-01-01| 23|         33|   NY|\n",
      "|  2|  Bob|2023-01-02| 30|         40|   CA|\n",
      "|  3|Cathy|2023-01-02| 45|         55|   TX|\n",
      "+---+-----+----------+---+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.join(df2, on=\"id\", how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+-----------+-----+\n",
      "| id| name|      date|age|age_plus_10|state|\n",
      "+---+-----+----------+---+-----------+-----+\n",
      "|  6|Frank|2023-01-01| 23|         33| NULL|\n",
      "|  1|Alice|2023-01-01| 23|         33|   NY|\n",
      "|  3|Cathy|2023-01-02| 45|         55|   TX|\n",
      "|  4|David|2023-01-03| 35|         45| NULL|\n",
      "|  5|  Eve|2023-01-03| 29|         39| NULL|\n",
      "|  2|  Bob|2023-01-02| 30|         40|   CA|\n",
      "+---+-----+----------+---+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.join(df2, on=\"id\", how=\"left\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+-----------+-----+\n",
      "| id| name|      date| age|age_plus_10|state|\n",
      "+---+-----+----------+----+-----------+-----+\n",
      "|  1|Alice|2023-01-01|  23|         33|   NY|\n",
      "|  2|  Bob|2023-01-02|  30|         40|   CA|\n",
      "|  3|Cathy|2023-01-02|  45|         55|   TX|\n",
      "|  4|David|2023-01-03|  35|         45| NULL|\n",
      "|  5|  Eve|2023-01-03|  29|         39| NULL|\n",
      "|  6|Frank|2023-01-01|  23|         33| NULL|\n",
      "|  7| NULL|      NULL|NULL|       NULL|   WA|\n",
      "+---+-----+----------+----+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.join(df2, on=\"id\", how=\"outer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot wider using `.pivot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+----+----+\n",
      "|      date|  23|  29|  30|  35|  45|\n",
      "+----------+----+----+----+----+----+\n",
      "|2023-01-03|NULL|   1|NULL|   1|NULL|\n",
      "|2023-01-01|   2|NULL|NULL|NULL|NULL|\n",
      "|2023-01-02|NULL|NULL|   1|NULL|   1|\n",
      "+----------+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot the data to show count of people per date\n",
    "pivoted_wide = people_df.groupBy(\"date\").pivot(\"age\").count()\n",
    "pivoted_wide.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot longer using `.unpivot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-----------+-----+\n",
      "| id| name|      date| age_column|value|\n",
      "+---+-----+----------+-----------+-----+\n",
      "|  6|Frank|2023-01-01|        age|   23|\n",
      "|  6|Frank|2023-01-01|age_plus_10|   33|\n",
      "|  1|Alice|2023-01-01|        age|   23|\n",
      "|  1|Alice|2023-01-01|age_plus_10|   33|\n",
      "|  3|Cathy|2023-01-02|        age|   45|\n",
      "|  3|Cathy|2023-01-02|age_plus_10|   55|\n",
      "|  4|David|2023-01-03|        age|   35|\n",
      "|  4|David|2023-01-03|age_plus_10|   45|\n",
      "|  5|  Eve|2023-01-03|        age|   29|\n",
      "|  5|  Eve|2023-01-03|age_plus_10|   39|\n",
      "|  2|  Bob|2023-01-02|        age|   30|\n",
      "|  2|  Bob|2023-01-02|age_plus_10|   40|\n",
      "+---+-----+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Must be same type for unpivot\n",
    "unpivot_df = (\n",
    "    people_df.select(\"id\", \"name\", \"date\", \"age\", \"age_plus_10\")\n",
    "    .unpivot(\n",
    "        ids=[\"id\", \"name\", \"date\"],\n",
    "        values=[\"age\", \"age_plus_10\"],\n",
    "        variableColumnName=\"age_column\",\n",
    "        valueColumnName=\"value\"\n",
    "    )\n",
    ")\n",
    "    \n",
    "unpivot_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting dates and timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------+--------------+\n",
      "|      date|   date_dt|            date_ts|formatted_date|\n",
      "+----------+----------+-------------------+--------------+\n",
      "|2023-01-01|2023-01-01|2023-01-01 00:00:00|    01/01/2023|\n",
      "|2023-01-01|2023-01-01|2023-01-01 00:00:00|    01/01/2023|\n",
      "|2023-01-02|2023-01-02|2023-01-02 00:00:00|    02/01/2023|\n",
      "|2023-01-03|2023-01-03|2023-01-03 00:00:00|    03/01/2023|\n",
      "|2023-01-03|2023-01-03|2023-01-03 00:00:00|    03/01/2023|\n",
      "|2023-01-02|2023-01-02|2023-01-02 00:00:00|    02/01/2023|\n",
      "+----------+----------+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_dates = (\n",
    "    people_df.withColumn(\"date_dt\", F.to_date(\"date\", \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"date_ts\", F.to_timestamp(\"date\", \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"formatted_date\", F.date_format(F.col(\"date_dt\"), \"dd/MM/yyyy\"))\n",
    ")\n",
    "\n",
    "df_dates.select(\"date\", \"date_dt\", \"date_ts\", \"formatted_date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping values from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---+-----------+------+\n",
      "| id| name|      date|age|age_plus_10|gender|\n",
      "+---+-----+----------+---+-----------+------+\n",
      "|  6|Frank|2023-01-01| 23|         33|     M|\n",
      "|  1|Alice|2023-01-01| 23|         33|     F|\n",
      "|  3|Cathy|2023-01-02| 45|         55|     F|\n",
      "|  4|David|2023-01-03| 35|         45|     M|\n",
      "|  5|  Eve|2023-01-03| 29|         39|     F|\n",
      "|  2|  Bob|2023-01-02| 30|         40|     M|\n",
      "+---+-----+----------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapping_dict = {\"Alice\": \"F\", \"Bob\": \"M\", \"Cathy\": \"F\", \"David\": \"M\", \"Eve\": \"F\", \"Frank\": \"M\"}\n",
    "\n",
    "mapping_expr = F.create_map([F.lit(x) for x in sum(mapping_dict.items(), ())])\n",
    "\n",
    "df_mapped = people_df.withColumn(\"gender\", mapping_expr[F.col(\"name\")])\n",
    "df_mapped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations with `.groupBy()`\n",
    "\n",
    "- Count rows\n",
    "- Count distinct ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|      date|row_count|distinct_ages|\n",
      "+----------+---------+-------------+\n",
      "|2023-01-03|        2|            2|\n",
      "|2023-01-01|        2|            1|\n",
      "|2023-01-02|        2|            2|\n",
      "+----------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_df = (\n",
    "    people_df.groupBy(\"date\")\n",
    "    .agg(F.count(\"id\").alias(\"row_count\"), F.countDistinct(\"age\").alias(\"distinct_ages\"))\n",
    ")\n",
    "agg_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
